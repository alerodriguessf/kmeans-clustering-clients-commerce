{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzqNIFUcadx46U3723U1Jy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alerodriguessf/kmeans-clustering-clients-commerce/blob/main/Portfolio_Clustering_Model_Kmeans_20250122.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Portfolio_Clustering Model_Kmeans_20250122"
      ],
      "metadata": {
        "id": "fb0w8Ahi1Bu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependency Installation\n",
        "\n",
        "!pip install sidetable yellowbrick\n",
        "!pip install ydata-profiling\n",
        "!pip install --upgrade matplotlib\n"
      ],
      "metadata": {
        "id": "TJM7MBatxefJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sidetable\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n"
      ],
      "metadata": {
        "id": "4cq7eVYzxjl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "id": "JzAan0A8xm7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 01) Exploratory Data Analysis**\n",
        "\n",
        "1. Load the dataset;\n",
        "2. Perform a statistical description of the data;\n",
        "3. Visualize distributions and identify the relevance of columns for analysis;\n",
        "4. Check for missing data, duplicates, outliers, and other inconsistencies"
      ],
      "metadata": {
        "id": "RG9ES0PNZOw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Loading the dataset;\n"
      ],
      "metadata": {
        "id": "WvgMdyNbNJyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame\n",
        "\n",
        "df = pd.read_csv('data.csv', encoding='latin1')"
      ],
      "metadata": {
        "id": "BBhGhQG71XKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Performing a statistical description of the data;\n"
      ],
      "metadata": {
        "id": "OnYEalNcNHEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a statistical description of the data;\n",
        "df.profile_report()"
      ],
      "metadata": {
        "id": "HgQ5pw0EbiJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates an initial report to explore the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XqXvPOzmxu3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess if all variables are of the correct type to apply possible changes during the preprocessing stage\n",
        "df.info()"
      ],
      "metadata": {
        "id": "JtNJAlytxwJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe"
      ],
      "metadata": {
        "id": "_mY9oJ8txy4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gUgeK-IdNV5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Visualizing distributions and identifying the relevance of columns for analysis;"
      ],
      "metadata": {
        "id": "lWpS29k4NbZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Identifying the number of unique values in two variables\n",
        "\n",
        "df[['Description', 'Country']].nunique()"
      ],
      "metadata": {
        "id": "5eaiy7do_x71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying outliers, negative values, and other inconsistencies in the data\n",
        "\n",
        "df[['Quantity','UnitPrice']].describe()"
      ],
      "metadata": {
        "id": "rh54lu4JALrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the distribution frequency by country to evaluate whether the country column makes sense to keep\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x=df['Country'], color='blue')\n",
        "plt.title('Distribuição dos paises')\n",
        "plt.xlabel('Paises')\n",
        "plt.ylabel('Frequência')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "02Pm9xm99SX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A simpler representation of country frequency\n",
        "df.stb.freq(['Country'])"
      ],
      "metadata": {
        "id": "xqzMcNwGAkDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the correlation between numerical variables\n",
        "corr = df.select_dtypes(include=np.number).corr()\n",
        "\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RJlRoaS--c4g",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.4 Checking for missing data, duplicates, outliers, and other inconsistencies\n",
        "\n",
        "### Although there is already a clear idea of the outliers based on the complete report from step 1"
      ],
      "metadata": {
        "id": "3lMYVJBdN2p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotted a boxplot to identify outliers in numerical variables\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(df[['Quantity', 'UnitPrice']])\n",
        "plt.title('Distribuição da quantidade e preço unitário')\n",
        "plt.ylabel('Quantidade e preço unitário')\n",
        "plt.xlabel('Frequência')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5iIdoKYz9_xy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum of null rows in each column\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "ld3fbjrEAhLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "df.stb.missing()"
      ],
      "metadata": {
        "id": "m0Q3s7pZx0QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying duplicate rows\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "9JzyQB5xA2x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 02) Data Preprocessing"
      ],
      "metadata": {
        "id": "zaquRBR4ZX18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Remove empty rows"
      ],
      "metadata": {
        "id": "wyTjI3tNOVdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all empty rows in the CustomerID field\n",
        "df=df.dropna(subset=['CustomerID'])"
      ],
      "metadata": {
        "id": "G6z54WYJzuiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the rows were removed\n",
        "df.stb.missing()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i6jtEfhR1dDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Adjust column types to be compatible with their respective contents"
      ],
      "metadata": {
        "id": "nVfwJ3zYOcPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns to data types compatible with their contents\n",
        "\n",
        "df['CustomerID'] = df['CustomerID'].astype(int)\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce', format = '%m/%d/%Y %H:%M')\n",
        "df['Country'] = df['Country'].astype('category')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RMUouNOdx3Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.copy()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yl2mXDDmz-i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirming that the types of each variable are correct\n",
        "df.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2nafeMAiCR6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Removing outliers and inconsistent values\n",
        "\n"
      ],
      "metadata": {
        "id": "XrEaZ9hsOprG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing negative values in columns\n",
        "below = df[['Quantity','UnitPrice']].le(0).any(axis=1)\n",
        "df = df[~below].copy()"
      ],
      "metadata": {
        "id": "VpvGYuciDDGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirming that negative values were excluded\n",
        "df[['Quantity','UnitPrice']].plot.box()"
      ],
      "metadata": {
        "id": "Vt0fiRrHCv11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing extreme outliers with reasonable limits\n",
        "df = df.query('Quantity <10_000 & UnitPrice <8_000')"
      ],
      "metadata": {
        "id": "xp_khc9mx8BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "iYtPhxo-1sAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Calculating the RFM (Recency, Frequency and monetary)\n"
      ],
      "metadata": {
        "id": "DWJ5We_HO1YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new column for the total purchase value\n",
        "df['price_total'] = df.Quantity * df.UnitPrice"
      ],
      "metadata": {
        "id": "Ap_rPsNOx9vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the RFM\n",
        "df_rfm = (\n",
        "    df.groupby('CustomerID')\n",
        "    .agg(\n",
        "        recency=('InvoiceDate', lambda x: (pd.Timestamp('2012-01-01') - x.max()).days),\n",
        "        frequency=('InvoiceNo', 'nunique'),\n",
        "        monetary=('price_total', 'mean')\n",
        "    )\n",
        ")\n",
        "\n",
        "df_rfm.head()"
      ],
      "metadata": {
        "id": "cTUuodTkyAtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assessing the distribution of the newly created columns\n",
        "df_rfm.plot.box()"
      ],
      "metadata": {
        "id": "aYaWfnhx1yJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 With the DataFrame adjusted for RFM values, I will standardize the data and repeat the process of removing outliers and inconsistent values\n"
      ],
      "metadata": {
        "id": "gSqGErApPAW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import scale"
      ],
      "metadata": {
        "id": "AZIU74P0FAXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "df_rfm.apply(scale).plot.box()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nZmD6ubYEzqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying outliers\n",
        "df_rfm.apply(scale).query('monetary > 50')"
      ],
      "metadata": {
        "id": "jWJ_Uih_FaTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check inconsistencies in this outlier\n",
        "df.query('CustomerID == 15098')"
      ],
      "metadata": {
        "id": "5UFUwTYVFmHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the outlier\n",
        "df_rfm = df_rfm.drop(15098)"
      ],
      "metadata": {
        "id": "7Q2BqScDGRyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Although the data will be normalized, it is already possible to identify outliers in the DataFrame\n",
        "df_rfm.describe()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-tX3vTq4IMTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotted a graph to visually represent outliers\n",
        "df_rfm.apply(scale).plot.box()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bzKeMevnGkKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers by replacing values above the 95th percentile with the 95th percentile value\n",
        "df_rfm_clip = df_rfm.apply(lambda x: x.clip(upper = x.quantile(0.95)))"
      ],
      "metadata": {
        "id": "p-W7_JLhIvs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirming that outliers were removed\n",
        "df_rfm_clip.describe()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nLWFUMm4JNf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = PowerTransformer()"
      ],
      "metadata": {
        "id": "RaYfI815HHlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing outliers using PowerTransformer\n",
        "df_rfm_scaled = pd.DataFrame(scaler.fit_transform(df_rfm), index=df_rfm.index, columns=df_rfm.columns)"
      ],
      "metadata": {
        "id": "NhxeriKjyJBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing cleaned data\n",
        "df_rfm_scaled.head()"
      ],
      "metadata": {
        "id": "qKibu64C19a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visually representing normalized data\n",
        "df_rfm_scaled.plot.box()"
      ],
      "metadata": {
        "id": "QfvuPSfgyRO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame with scaled and outlier-free data for clustering\n",
        "df_rfm_clip_scaled = df_rfm_clip.apply(scale)"
      ],
      "metadata": {
        "id": "d0L63rutJX3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 03) Select a clustering algorithm\n",
        "\n",
        "1. Choose a suitable algorithm for the dataset, such as KMeans, DBSCAN, Hierarchical, or Mean Shift\n",
        "2. Find the optimal number of clusters using the Elbow or Silhouette Score methods\n",
        "3. Implement the chosen algorithm\n"
      ],
      "metadata": {
        "id": "oR_2pU_GZlIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Choosing KMeans to determine the optimal number of clusters\n",
        "\n",
        "#### **I chose to use K-Means to define the number of clusters** because it is a simple, efficient method well-suited to this type of analysis and the dataset used in the challenge. K-Means works well for identifying approximately spherical and convex clusters, as seen in the context of RFM analysis (Recency, Frequency, and Monetary), where groups tend to follow this characteristic. K-Means is flexible, handles outliers well, and is easily interpretable.\n"
      ],
      "metadata": {
        "id": "u5qQuv-jP7zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer"
      ],
      "metadata": {
        "id": "QuQaPyvg2Jxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Finding the optimal number of clusters using the Elbow and Silhouette Score methods"
      ],
      "metadata": {
        "id": "uzhioVAhCcoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Identifying the ideal number of clusters using the Elbow method\n",
        "\n",
        "model = KMeans()\n",
        "visualizer = KElbowVisualizer(model, k=(2,8), timings=False)\n",
        "visualizer.fit(df_rfm_clip_scaled)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "P___kEDl2LZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the optimal number of clusters based on key clustering quality indicators\n",
        "cluster_metrics = silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "cluster_metrics_results = []\n",
        "x = df_rfm_clip_scaled.copy()\n",
        "\n",
        "for k in range(2, min(x.shape[0], 11)):\n",
        "    model = KMeans(n_clusters=k, random_state=0)\n",
        "    labels = model.fit_predict(x)\n",
        "    cluster_results_dict = {'k': k}\n",
        "    cluster_results_dict['inertia'] = model.inertia_\n",
        "    for metric in cluster_metrics:\n",
        "        cluster_results_dict[metric.__name__] = metric(x, labels)\n",
        "    cluster_metrics_results.append(cluster_results_dict)\n",
        "\n",
        "cluster_metrics_results\n",
        "\n",
        "pd.DataFrame(cluster_metrics_results).set_index('k').style.background_gradient()"
      ],
      "metadata": {
        "id": "RCCuqmXK2Q2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After analyzing the metrics, everything seems to indicate that **4 clusters offer the best balance between cohesion and separation of groups**\n",
        "\n",
        "###**Inertia**: The significant reduction in inertia stabilizes after k=4, meaning more clusters add little improvement.\n",
        "\n",
        "###**Silhouette Score**: The maximum value at k=4 (0.479) shows good cohesion and separation between clusters.\n",
        "\n",
        "###**Davies-Bouldin Score**: The lowest value occurs at k=4 (0.704), suggesting an optimal separation.\n",
        "\n",
        "###**Calinski-Harabasz Index**: The highest value at k=4 (3751) highlights greater distinction between clusters.\n",
        "\n",
        "## 3.3 Implementing the chosen algorithm\n"
      ],
      "metadata": {
        "id": "7dE1Y6ShK2h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Implementing the chosen algorithm\n"
      ],
      "metadata": {
        "id": "jnWQGqPKXOQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model with the optimal number of clusters\n",
        "kmeans = KMeans(4)\n",
        "kmeans_labels = kmeans.fit_predict(df_rfm_clip_scaled)"
      ],
      "metadata": {
        "id": "LevGqjxT2W7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D visual representation of the clusters\n",
        "px.scatter_3d(df_rfm_clip, x='recency', y='frequency', z='monetary', color=kmeans_labels, template='plotly_dark')"
      ],
      "metadata": {
        "id": "31NBV4xF2aKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 04) Analyze the clusters obtained from KMeans\n",
        "\n",
        "1. Identify patterns and common characteristics among customers\n",
        "2. Plot graphs to assist in the analysis"
      ],
      "metadata": {
        "id": "0Z4bJHZMZuLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Identifying patterns and common characteristics among customers"
      ],
      "metadata": {
        "id": "xCSOKXyApTik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Presenting the profiles of each cluster based on the RFM metric\n",
        "\n",
        "df_rfm_clip['cluster'] = kmeans.labels_\n",
        "\n",
        "cluster_profiles = df_rfm_clip.groupby('cluster').mean()\n",
        "print(\"Perfis dos Clusters:\\n\", cluster_profiles)"
      ],
      "metadata": {
        "id": "L25XmiicDLZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a DataFrame with normalized cluster data\n",
        "centers = pd.DataFrame(kmeans.cluster_centers_, columns=df_rfm_clip_scaled.columns)\n",
        "centers"
      ],
      "metadata": {
        "id": "xu0TIl153Xdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_profiles_z = (cluster_profiles - cluster_profiles.mean()) / cluster_profiles.std()\n",
        "print(\"Z-Scores dos Clusters:\\n\", cluster_profiles_z)\n"
      ],
      "metadata": {
        "id": "JUYTMXHNrjfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Plotting graphs to assist in the analysis"
      ],
      "metadata": {
        "id": "ehRHNmchpaYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cluster_profiles_z.T, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Divergência dos Clusters em Relação à Média Global\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "b8Lv2PhErnSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"recency\", \"frequency\", \"monetary\"]:\n",
        "    sns.boxplot(x=\"cluster\", y=col, data=df_rfm_clip.reset_index())\n",
        "    plt.title(f\"Distribuição de {col} por Cluster\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AZxZgnysrL4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visual representation of normalized cluster data\n",
        "\n",
        "fig,axes = plt.subplots(nrows=4, figsize=(14,12), sharex=True)\n",
        "\n",
        "for i,ax in enumerate(axes):\n",
        "  center = centers.loc[i,:]\n",
        "  maxPC = 1.01 * center.abs().max()\n",
        "  colors = ['green' if l > 0 else 'red' for l in center]\n",
        "  center.plot.bar(ax=ax, color=colors)\n",
        "  ax.set_ylabel(f'Cluster {i+1}')\n",
        "  ax.set_ylim(-maxPC, maxPC)\n",
        "  ax.axhline(color='gray')\n",
        "  ax.xaxis.set_ticks_position('none')\n",
        "\n",
        "plt.xticks(rotation=60, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z7H3T8fX3m0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual representation of clusters based on RFM indicators\n",
        "\n",
        "(\n",
        " df_rfm_clip.assign(cluster= kmeans_labels)\n",
        " .groupby('cluster')\n",
        " .mean()\n",
        " .transpose()\n",
        " .style.background_gradient(cmap='YlOrRd', axis=1)\n",
        ")"
      ],
      "metadata": {
        "id": "SQnFHUQlWTwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 05) Interpret the results obtained\n",
        "\n",
        "1. Describe the purchasing profile of customers in each cluster\n",
        "2. Justify how this analysis can be useful for the company to segment its customers and personalize marketing campaigns\n",
        "3. Suggest possible actions based on the analyses performed"
      ],
      "metadata": {
        "id": "Nvo5HQ5qa2sS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5.1 Description of Customer Purchasing Profile by Cluster\n",
        "\n",
        "**Cluster 1: Inactive Low-Value Customers**\n",
        "\n",
        "Recency: 260 days (customers who haven’t purchased for a long time).\n",
        "\n",
        "Frequency: 1.5 purchases on average (infrequent customers).\n",
        "\n",
        "Monetary: $18.10 on average (very low average spend).\n",
        "\n",
        "Profile: Sporadic customers, low retention, and little-added value.\n",
        "\n",
        "**Cluster 2: Moderately Active Low-Value Customers**\n",
        "\n",
        "Recency: 67 days (more recently engaged customers).\n",
        "\n",
        "Frequency: 2.7 purchases on average (moderate frequency customers).\n",
        "\n",
        "Monetary: $17.12 on average (low average spend).\n",
        "\n",
        "Profile: Customers who make occasional purchases but still have low financial impact.\n",
        "\n",
        "**Cluster 3: Active High-Value Customers**\n",
        "\n",
        "Recency: 121 days (relatively active but not recent customers).\n",
        "\n",
        "Frequency: 3.9 purchases on average (frequent customers).\n",
        "\n",
        "Monetary: $80.71 on average (high average spend per customer).\n",
        "\n",
        "Profile: Regular customers with high value for the company.\n",
        "\n",
        "**Cluster 4: Recent and Very Frequent Customers**\n",
        "\n",
        "Recency: 41 days (recent customers).\n",
        "\n",
        "Frequency: 10.2 purchases on average (highly frequent customers).\n",
        "\n",
        "Monetary: $20.43 on average (moderate average spend).\n",
        "\n",
        "Profile: Engaged customers who buy frequently but with relatively low ticket sizes."
      ],
      "metadata": {
        "id": "XU1SinGeYPok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.2 Justifying how this analysis can be useful for the company to segment its customers and personalize marketing campaigns\n",
        "\n",
        "**Segmentation**: The analysis allows targeted campaigns for each profile, optimizing resources and increasing effectiveness.\n",
        "\n",
        "**Personalization**: Identifying needs and behavioral patterns helps create personalized offers and improve the customer experience.\n",
        "\n",
        "**Retention**: Focus on higher-value clusters (2 and 3) to retain these customers and increase their lifecycle value.\n"
      ],
      "metadata": {
        "id": "ti1e4KKBYF5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Suggesting possible actions based on the analyses performed\n",
        "\n",
        "**Cluster 1:** Inactive Low-Value Customers\n",
        "\n",
        "Strategy: Reactivation campaigns, such as personalized discount emails or suggested products.\n",
        "\n",
        "Incentive: Offer exclusive promotions for the next purchase.\n",
        "\n",
        "**Cluster 2:** Moderately Active Low-Value Customers\n",
        "\n",
        "Strategy: Increase spend with product packages or combos.\n",
        "\n",
        "Incentive: Offer a basic loyalty program to encourage more frequent purchases.\n",
        "\n",
        "**Cluster 3:** Active High-Value Customers\n",
        "\n",
        "Strategy: Retain and increase engagement through VIP programs or exclusive offers.\n",
        "\n",
        "Incentive: Create an exclusive communication channel for these customers with benefits like early access to launches.\n",
        "\n",
        "**Cluster 4:** Recent and Very Frequent Customers\n",
        "\n",
        "Strategy: Encourage higher-value purchases to increase average ticket size.\n",
        "\n",
        "Incentive: Offer promotions based on purchase volume or recommend complementary products.\n"
      ],
      "metadata": {
        "id": "vj7pffl8ZRlI"
      }
    }
  ]
}